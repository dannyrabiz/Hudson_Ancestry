{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4575b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import time\n",
    "# Define the local path where you want to save the file\n",
    "\n",
    "bed_path = '/home/jupyter/top_aims_hg38.bed'\n",
    "#for i in range(df_manifest.shape[0])\n",
    "cnt = 0 \n",
    "for i in range(4):\n",
    "    a = time.time()\n",
    "    # Define the path to your file in the GCS bucket\n",
    "    vcf_gcs_path = df_manifest.loc[i]['vcf_file_location']\n",
    "    local_vcf_path = vcf_gcs_path.split('/')[-1]\n",
    "    ID = local_vcf_path.split('-')[0]\n",
    "    # Use gsutil to copy the file from GCS to the local environment\n",
    "    os.system(f'gsutil cp {vcf_gcs_path} {local_vcf_path}')\n",
    "    os.system(f'gsutil cp {vcf_gcs_path}.tbi {local_vcf_path}.tbi')\n",
    "    #vcf_file = pysam.VariantFile(vcf_path)\n",
    "    os.system(f'bedtools intersect -a {local_vcf_path} -b {bed_path} > /home/jupyter/{ID}.vcf')\n",
    "    os.system(f'rm {local_vcf_path}; rm {local_vcf_path}.tbi')\n",
    "    cnt +=1\n",
    "    print(time.time()-a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18ff2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat /home/jupyter/*vcf > /home/jupyter/Merged.vcf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab420d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Import the vcf file\n",
    "vcf = pd.read_csv('/home/jupyter/Merged.vcf', sep ='\\t', header = None)\n",
    "vcf.columns = list(header.loc[0])\n",
    "vcf = vcf[vcf['FILTER']=='.']\n",
    "#remove multiallelic? Or just set it regular \n",
    "vcf = vcf[~vcf['ALT'].str.contains(',')]\n",
    "vcf = vcf[~vcf['INFO'].str.contains('AC=0')]\n",
    "#vcf = vcf[~vcf['INFO'].str.contains('AC=1;')]\n",
    "#vcf = vcf[~vcf['#CHROM'].str.contains('chrY')]\n",
    "vcf = vcf[vcf['REF'].apply(len)==1]\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming vcf and bed_file are your DataFrames\n",
    "vcf.rename(columns={'#CHROM': 'Chr', 'POS': 'Start'}, inplace=True)\n",
    "\n",
    "\n",
    "# Rename columns for clarity\n",
    "bed_file.columns = ['Chr', 'Start', 'End', 'Ancestry_NucleotideChange', 'Score', 'Strand']\n",
    "\n",
    "# Merge on 'Chr' and 'Start' columns\n",
    "merged_df = pd.merge(vcf, bed_file, how='inner', on=['Chr', 'Start'])\n",
    "\n",
    "# Extract the Ref and Alt from the Ancestry_NucleotideChange column in bed_file\n",
    "merged_df[['Ancestry', 'Nucleotide_Change']] = merged_df['Ancestry_NucleotideChange'].str.split('_', expand=True)\n",
    "merged_df[['Ref_bed', 'Alt_bed']] = merged_df['Nucleotide_Change'].str.split('>', expand=True)\n",
    "\n",
    "# Filter to keep only rows where the REF and ALT in vcf match the ones in bed_file\n",
    "filtered_vcf = merged_df[(merged_df['REF'] == merged_df['Ref_bed']) & (merged_df['ALT'] == merged_df['Alt_bed'])]\n",
    "\n",
    "#Save Ancestry\n",
    "ancestry = filtered_vcf['Ancestry'] \n",
    "\n",
    "# Drop the extra columns used for filtering\n",
    "filtered_vcf = filtered_vcf.drop(columns=['End', 'Ancestry_NucleotideChange', 'Score', 'Strand', 'Ancestry', 'Nucleotide_Change', 'Ref_bed', 'Alt_bed'])\n",
    "\n",
    "# Resulting filtered_vcf DataFrame contains only the desired variants\n",
    "#print(filtered_vcf)\n",
    "#split chrx and all other chromosomes \n",
    "vcfX = filtered_vcf[filtered_vcf['Chr'].str.contains('chrX')]\n",
    "vcf = filtered_vcf[~filtered_vcf['Chr'].str.contains('chrX')]\n",
    "# Define a function to substitute genotype values\n",
    "def substitute_genotype(value):\n",
    "    if value.startswith('1/1'):\n",
    "        return 2\n",
    "    elif value.startswith('0/1') or value.startswith('1/0'):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "    \n",
    "def substitute_genotype_chromX(value):\n",
    "    if value.startswith('1/1'):\n",
    "        return 1\n",
    "    elif value.startswith('0/1') or value.startswith('1/0'):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "# Apply the function to each column in the genomic info columns\n",
    "vcf[vcf.columns[9:]] = vcf[vcf.columns[9:]].applymap(substitute_genotype)\n",
    "\n",
    "# Display the modified DataFrame\n",
    "#print(vcf.head())\n",
    "\n",
    "vcfX[vcfX.columns[9:]] = vcfX[vcfX.columns[9:]].applymap(substitute_genotype_chromX)\n",
    "\n",
    "vcf = vcf[vcf.columns[9:]]\n",
    "vcfX = vcfX[vcfX.columns[9:]]\n",
    "master_df = pd.concat([vcf,vcfX])\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming master_df is your DataFrame with sample names as columns\n",
    "# And ancestry is a pandas Series where each entry corresponds to the ancestry of the row in master_df\n",
    "\n",
    "# Group by ancestry and sum the values for each sample\n",
    "summed_df = master_df.groupby(ancestry).sum()\n",
    "\n",
    "# Transpose the DataFrame so that rows become samples and columns become ancestries\n",
    "summed_df = summed_df.T\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "#print(summed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1558bd95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736ad46f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3a51f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7860a021",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "keep_index = vcf[vcf.columns[0:5]]\n",
    "keep_index_X = vcfX[vcfX.columns[0:5]]\n",
    "variant_df = pd.concat([keep_index,keep_index_X])\n",
    "vcf = vcf[vcf.columns[9:]]\n",
    "vcfX = vcfX[vcfX.columns[9:]]\n",
    "train_df = pd.concat([vcf,vcfX])\n",
    "copy_train_df = train_df.copy()\n",
    "# 1. Create ethnicity labels for the samples\n",
    "# Create a dictionary with the ethnicity labels\n",
    "ethnicity_map = {sample: 'AFR' for sample in AFR}\n",
    "#ethnicity_map.update({sample: 'ASJ' for sample in ASJ})\n",
    "ethnicity_map.update({sample: 'EAS' for sample in EAS})\n",
    "ethnicity_map.update({sample: 'AMR' for sample in AMR})\n",
    "ethnicity_map.update({sample: 'SAS' for sample in SAS})\n",
    "ethnicity_map.update({sample: 'EUR' for sample in EUR})\n",
    "\n",
    "train_df = train_df[ethnicity_map.keys()]\n",
    "\n",
    "# Create the labels (y) for each sample\n",
    "samples = train_df.columns\n",
    "y = np.array([ethnicity_map[sample] for sample in samples])\n",
    "\n",
    "# 2. Transpose the train_df so that samples are rows and variants are columns\n",
    "X = train_df.T  # Now each row is a sample and each column is a variant\n",
    "\n",
    "# 3. Feature selection: Remove low-variance features (variants)\n",
    "selector = VarianceThreshold(threshold=0.4)  # You can adjust the threshold\n",
    "X_selected = selector.fit_transform(X)\n",
    "\n",
    "# 4. Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.3, random_state=42)\n",
    "Random Forest\n",
    "# 5. Train a random forest classifier\n",
    "clf = RandomForestClassifier(n_estimators=75, random_state=41)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# 6. Make predictions on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# 7. Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model accuracy: {accuracy}\")\n",
    "Model accuracy: 0.9597701149425287\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred, labels=np.unique(y_test))\n",
    "\n",
    "# Create a DataFrame for easier visualization\n",
    "cm_df = pd.DataFrame(cm, index=np.unique(y_test), columns=np.unique(y_test))\n",
    "\n",
    "# Visualize the confusion matrix using a heatmap\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm_df, annot=True, fmt='g', cmap='Blues')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('True Ethnicity')\n",
    "plt.xlabel('Predicted Ethnicity')\n",
    "plt.show()\n",
    "\n",
    "# Display classification report\n",
    "print(classification_report(y_test, y_pred, target_names=np.unique(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2c8b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC(kernel='rbf', random_state=42)\n",
    "svc.fit(X_train, y_train)\n",
    "y_pred_svc = svc.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred_svc)\n",
    "print(f\"Model accuracy: {accuracy}\")\n",
    "Model accuracy: 0.9770114942528736\n",
    "clf.classes_\n",
    "array(['AFR', 'AMR', 'EAS', 'EUR', 'SAS'], dtype='<U3')\n",
    "y_predictions = []\n",
    "# Assuming y_test contains the true ethnicity labels for the test samples\n",
    "# y_test should be aligned with the indices of X_test\n",
    "\n",
    "# Train an SVM model with probability=True to enable probability predictions\n",
    "svc = SVC(kernel='rbf', probability=True, random_state=42)\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "# Predict probabilities\n",
    "y_proba = svc.predict_proba(X_test)\n",
    "\n",
    "\n",
    "# Predict probabilities using Random Forest\n",
    "\n",
    "\n",
    "# Iterate through each sample's probabilities and show the true ethnicity label\n",
    "for i, probs in enumerate(y_proba):\n",
    "    sorted_indices = probs.argsort()[::-1]  # Sort in descending order\n",
    "    top_1 = sorted_indices[0]  # Index of the primary ethnicity\n",
    "    top_2 = sorted_indices[1]  # Index of the second highest ethnicity (admixture likelihood)\n",
    "    \n",
    "    # Get the true ethnicity from y_test\n",
    "    true_ethnicity = y_test[i]\n",
    "    \n",
    "    # Apply the rule: If primary ethnicity is EUR and prob < 0.60, and second highest is ASJ with prob > 0.30\n",
    "    if (clf.classes_[top_1] == 'EUR' and probs[top_1] < 0.60) and (clf.classes_[top_2] == 'ASJ' and probs[top_2] > 0.30):\n",
    "        predicted_ethnicity = 'ASJ'\n",
    "        print('FREEZE')\n",
    "        print(f\"Sample {i+1}: True Ethnicity: {true_ethnicity}\")\n",
    "        print(f\"Rule applied: Changed predicted ethnicity from EUR to ASJ\")\n",
    "    else:\n",
    "        predicted_ethnicity = clf.classes_[top_1]\n",
    "        print(f\"Sample {i+1}: True Ethnicity: {true_ethnicity}\")\n",
    "        print(f\"Primary Predicted Ethnicity: {predicted_ethnicity} with probability {probs[top_1]:.4f}\")\n",
    "\n",
    "    print(f\"Possible Admixture: {clf.classes_[top_2]} with probability {probs[top_2]:.4f}\")\n",
    "    print(\"-\" * 30)\n",
    "    y_predictions.append(predicted_ethnicity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4016f3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test, y_predictions)\n",
    "print(f\"Model accuracy: {accuracy}\")\n",
    "Model accuracy: 1.0\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_predictions, labels=np.unique(y_test))\n",
    "\n",
    "# Create a DataFrame for easier visualization\n",
    "cm_df = pd.DataFrame(cm, index=np.unique(y_test), columns=np.unique(y_test))\n",
    "\n",
    "# Visualize the confusion matrix using a heatmap\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm_df, annot=True, fmt='g', cmap='Blues')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('True Ethnicity')\n",
    "plt.xlabel('Predicted Ethnicity')\n",
    "plt.show()\n",
    "\n",
    "# Display classification report\n",
    "#print(classification_report(y_test, y_pred, target_names=np.unique(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b592c041",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Assuming X_selected is the transformed feature matrix after selection\n",
    "# and variant_df contains information about the variants (with rows corresponding to variants in train_df)\n",
    "\n",
    "# Get the indices of selected variants\n",
    "selected_variant_indices = selector.get_support(indices=True)\n",
    "\n",
    "# Extract the corresponding rows from variant_df based on the selected indices\n",
    "selected_variants = variant_df.iloc[selected_variant_indices]\n",
    "\n",
    "# Save the selected variant indices for future reference\n",
    "selected_variants_file = '/home/jupyter/new_selected_variants.pkl'\n",
    "joblib.dump(selected_variant_indices, selected_variants_file)\n",
    "print(f\"Selected variant indices saved to {selected_variants_file}\")\n",
    "\n",
    "# Optionally, save the entire selected variants DataFrame\n",
    "selected_variants_df_file = '/home/jupyter/new_selected_variants_df.pkl'\n",
    "selected_variants.to_pickle(selected_variants_df_file)\n",
    "print(f\"Selected variant details saved to {selected_variants_df_file}\")\n",
    "Selected variant indices saved to /home/jupyter/new_selected_variants.pkl\n",
    "Selected variant details saved to /home/jupyter/new_selected_variants_df.pkl\n",
    "# Save the trained SVM model\n",
    "svm_model_file = '/home/jupyter/new_svm_model.pkl'\n",
    "joblib.dump(svc, svm_model_file)  # Assuming svc is your trained SVM model\n",
    "print(f\"SVM model saved to {svm_model_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
